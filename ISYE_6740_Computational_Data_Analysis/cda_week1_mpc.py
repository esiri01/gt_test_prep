module_1_lecture_transcripts_question_1 = {
    'question': "What is the primary goal of machine learning as described in the lecture?",
    'options_list': [
        'To store and retrieve large datasets',
        'To process data and extract useful information',
        'To create complex mathematical models for academic purposes',
        'To perform manual calculations on large data'
    ],
    'correct_answer': 'To process data and extract useful information',
    'explanation': "The primary goal of machine learning is to optimize data processing to extract useful information, such as making predictions or classifications.",
    'chapter_information': 'Module 1 Lecture Transcripts'
}

module_1_lecture_transcripts_question_2 = {
    'question': "Which of the following applications is related to the task of clustering?",
    'options_list': [
        'Classifying emails as spam',
        'Organizing images based on similarities',
        'Predicting weather conditions',
        'Recommending products to users'
    ],
    'correct_answer': 'Organizing images based on similarities',
    'explanation': "Clustering involves organizing data, such as images, into groups based on similarities.",
    'chapter_information': 'Module 1 Lecture Transcripts'
}

module_1_lecture_transcripts_question_3 = {
    'question': "In the context of community detection in social networks, what does an 'edge' typically represent?",
    'options_list': [
        'A specific user in the network',
        'A connection between two users',
        'A distinct community within the network',
        'The total number of users in the network'
    ],
    'correct_answer': 'A connection between two users',
    'explanation': "An 'edge' in network data represents a connection or interaction between two users (nodes) in the network.",
    'chapter_information': 'Module 1 Lecture Transcripts'
}

module_1_lecture_transcripts_question_4 = {
    'question': "Which method is commonly used for non-linear classification in high-dimensional data?",
    'options_list': [
        'Linear regression',
        'Principal Component Analysis (PCA)',
        'Kernel methods',
        'Bag-of-words model'
    ],
    'correct_answer': 'Kernel methods',
    'explanation': "Kernel methods are often used to perform non-linear classification, especially in high-dimensional spaces.",
    'chapter_information': 'Module 1 Lecture Transcripts'
}

module_1_lecture_transcripts_question_5 = {
    'question': "What is the purpose of the least squares method in linear regression?",
    'options_list': [
        'To maximize the likelihood function',
        'To find the parameters that minimize the sum of squared errors',
        'To perform dimensionality reduction',
        'To identify clusters in the data'
    ],
    'correct_answer': 'To find the parameters that minimize the sum of squared errors',
    'explanation': "The least squares method aims to minimize the sum of squared errors between the observed data points and the modelâ€™s predictions.",
    'chapter_information': 'Module 1 Lecture Transcripts'
}

module_1_lecture_transcripts_question_6 = {
    'question': "Which model is frequently used in speech recognition to capture dependencies in sequential data?",
    'options_list': [
        'Latent Semantic Indexing (LSI)',
        'Hidden Markov Model (HMM)',
        'Support Vector Machine (SVM)',
        'Gradient Descent'
    ],
    'correct_answer': 'Hidden Markov Model (HMM)',
    'explanation': "Hidden Markov Models (HMMs) are used in speech recognition to model the sequence of spoken words and their dependencies.",
    'chapter_information': 'Module 1 Lecture Transcripts'
}

module_1_lecture_transcripts_question_7 = {
    'question': "What does the term 'matrix completion' refer to in the context of product recommendation systems?",
    'options_list': [
        'Filling in missing entries in a user-item matrix',
        'Clustering products into distinct categories',
        'Reducing the dimensions of a large matrix',
        'Identifying outliers in a dataset'
    ],
    'correct_answer': 'Filling in missing entries in a user-item matrix',
    'explanation': "Matrix completion refers to predicting the missing values in a user-item matrix, which is used for making product recommendations.",
    'chapter_information': 'Module 1 Lecture Transcripts'
}

module_1_lecture_transcripts_question_8 = {
    'question': "Which of the following is NOT a key component required for building a machine learning model according to the lecture?",
    'options_list': [
        'Programming skills',
        'Probability and statistics',
        'Knowledge of chemistry',
        'Linear algebra'
    ],
    'correct_answer': 'Knowledge of chemistry',
    'explanation': "While programming, probability, statistics, and linear algebra are essential, chemistry is not a required component for building a machine learning model.",
    'chapter_information': 'Module 1 Lecture Transcripts'
}

module_1_lecture_transcripts_question_9 = {
    'question': "In the context of novelty and anomaly detection, what is typically the input data?",
    'options_list': [
        'Historical weather patterns',
        'Labeled normal and abnormal data',
        'A large text corpus',
        'High-dimensional image data'
    ],
    'correct_answer': 'Labeled normal and abnormal data',
    'explanation': "The input data in novelty and anomaly detection usually consists of labeled normal data and sometimes abnormal data, to detect outliers or novelties.",
    'chapter_information': 'Module 1 Lecture Transcripts'
}

module_1_lecture_transcripts_question_10 = {
    'question': "Which of the following approaches is suggested when the inversion of a matrix in the least squares method becomes computationally expensive?",
    'options_list': [
        'Latent Semantic Indexing',
        'Kernel Trick',
        'Gradient Descent',
        'Support Vector Machine'
    ],
    'correct_answer': 'Gradient Descent',
    'explanation': "Gradient Descent is used as an iterative optimization approach when direct matrix inversion is computationally expensive or infeasible.",
    'chapter_information': 'Module 1 Lecture Transcripts'
}

module_1_lecture_transcripts_question_11 = {
    'question': "Suppose you have a simple linear regression model \( y = 3x + 2 \). If \( x = 4 \), what is the predicted value of \( y \)?",
    'options_list': [
        '10',
        '12',
        '14',
        '20'
    ],
    'correct_answer': '14',
    'explanation': "Substituting \( x = 4 \) into the equation \( y = 3x + 2 \), you get \( y = 3(4) + 2 = 14 \).",
    'chapter_information': 'Module 1 Lecture Transcripts'
}

module_1_lecture_transcripts_question_12 = {
    'question': "Given a dataset with two features \( x_1 \) and \( x_2 \), and the linear model \( y = \theta_0 + \theta_1 x_1 + \theta_2 x_2 \), if \( \theta_0 = 1 \), \( \theta_1 = 2 \), \( \theta_2 = 3 \), and the input \( x_1 = 2 \), \( x_2 = 1 \), what is the predicted value of \( y \)?",
    'options_list': [
        '6',
        '7',
        '8',
        '9'
    ],
    'correct_answer': '8',
    'explanation': "Substitute the values into the model: \( y = 1 + 2(2) + 3(1) = 8 \).",
    'chapter_information': 'Module 1 Lecture Transcripts'
}

module_1_lecture_transcripts_question_13 = {
    'question': "Consider a small dataset with the following points: \((1, 2)\), \((2, 4)\), \((3, 5)\). Calculate the mean of the dependent variable \( y \).",
    'options_list': [
        '2',
        '3',
        '4',
        '5'
    ],
    'correct_answer': '3.67',
    'explanation': "The mean of \( y \) is \( \frac{2 + 4 + 5}{3} = 3.67 \).",
    'chapter_information': 'Module 1 Lecture Transcripts'
}

module_1_lecture_transcripts_question_14 = {
    'question': "Using the same dataset \((1, 2)\), \((2, 4)\), \((3, 5)\), calculate the sum of squared errors (SSE) if the model is \( y = 2x \).",
    'options_list': [
        '0.5',
        '1',
        '2',
        '3'
    ],
    'correct_answer': '1',
    'explanation': "The SSE is calculated as \( (2 - 2)^2 + (4 - 4)^2 + (5 - 6)^2 = 1 \).",
    'chapter_information': 'Module 1 Lecture Transcripts'
}

module_1_lecture_transcripts_question_15 = {
    'question': "If you are given two features \( x_1 = 3 \) and \( x_2 = 4 \), calculate the Euclidean distance between these two features.",
    'options_list': [
        '1',
        '2',
        '5',
        '7'
    ],
    'correct_answer': '5',
    'explanation': "The Euclidean distance between \( x_1 \) and \( x_2 \) is \( \sqrt{(3 - 0)^2 + (4 - 0)^2} = 5 \).",
    'chapter_information': 'Module 1 Lecture Transcripts'
}

module_1_lecture_transcripts_question_16 = {
    'question': "For a linear model \( y = \theta_1 x_1 + \theta_2 x_2 + \epsilon \), where \( \epsilon \) is the error term and follows a normal distribution \( N(0, \sigma^2) \), if \( y = 10 \), \( \theta_1 = 2 \), \( \theta_2 = 3 \), \( x_1 = 2 \), \( x_2 = 1 \), what is the value of the error term \( \epsilon \)?",
    'options_list': [
        '0',
        '1',
        '2',
        '-1'
    ],
    'correct_answer': '2',
    'explanation': "First calculate \( \hat{y} = \theta_1 x_1 + \theta_2 x_2 = 2(2) + 3(1) = 7 \). The error term \( \epsilon = y - \hat{y} = 10 - 7 = 3 \).",
    'chapter_information': 'Module 1 Lecture Transcripts'
}

module_1_lecture_transcripts_question_17 = {
    'question': "Given the following probabilities \( P(A) = 0.4 \), \( P(B) = 0.3 \), and \( P(A \cap B) = 0.1 \), compute \( P(A \cup B) \).",
    'options_list': [
        '0.5',
        '0.6',
        '0.7',
        '0.8'
    ],
    'correct_answer': '0.6',
    'explanation': "Use the formula \( P(A \cup B) = P(A) + P(B) - P(A \cap B) = 0.4 + 0.3 - 0.1 = 0.6 \).",
    'chapter_information': 'Module 1 Lecture Transcripts'
}

module_1_lecture_transcripts_question_18 = {
    'question': "If a small dataset consists of 3 data points \((x_1, y_1)\), \((x_2, y_2)\), and \((x_3, y_3)\) where \( y = 2x + 1 \), and the data points are \((1, 3)\), \((2, 5)\), and \((3, 7)\), compute the value of the loss function \( L(\theta) = \frac{1}{n} \sum_{i=1}^{n} (y^{(i)} - \hat{y}^{(i)})^2 \) for this model.",
    'options_list': [
        '0',
        '0.5',
        '1',
        '2'
    ],
    'correct_answer': '0',
    'explanation': "Since \( y^{(i)} = \hat{y}^{(i)} \) for all points, the loss function \( L(\theta) = 0 \).",
    'chapter_information': 'Module 1 Lecture Transcripts'
}

module_1_lecture_transcripts_question_19 = {
    'question': "Suppose you have two vectors \( \mathbf{x} = [2, 3] \) and \( \mathbf{\theta} = [4, 5] \). Calculate the dot product \( \mathbf{\theta}^T \mathbf{x} \).",
    'options_list': [
        '23',
        '25',
        '26',
        '28'
    ],
    'correct_answer': '23',
    'explanation': "The dot product \( \mathbf{\theta}^T \mathbf{x} = 4(2) + 5(3) = 23 \).",
    'chapter_information': 'Module 1 Lecture Transcripts'
}

module_1_lecture_transcripts_question_20 = {
    'question': "Given a simple linear regression model \( y = 5x - 3 \), calculate the gradient with respect to \( x \) when \( x = 2 \).",
    'options_list': [
        '5',
        '7',
        '10',
        '12'
    ],
    'correct_answer': '5',
    'explanation': "The gradient of \( y = 5x - 3 \) with respect to \( x \) is 5, which is constant regardless of \( x \).",
    'chapter_information': 'Module 1 Lecture Transcripts'
}

minkowski_metric_paper_question_1 = {
    'question': "What is one of the main drawbacks of the K-Means algorithm addressed by this paper?",
    'options_list': [
        'Lack of defense against noisy features',
        'High computational complexity',
        'Difficulty in handling large datasets',
        'Poor performance with non-Euclidean distances'
    ],
    'correct_answer': 'Lack of defense against noisy features',
    'explanation': "The paper focuses on addressing the issue of K-Means' lack of defense against noisy features by incorporating feature weights.",
    'chapter_information': 'Minkowski Metric Paper'
}

minkowski_metric_paper_question_2 = {
    'question': "Which metric does the paper extend the Weighted K-Means method to?",
    'options_list': [
        'Euclidean metric',
        'Minkowski metric',
        'Manhattan metric',
        'Chebyshev metric'
    ],
    'correct_answer': 'Minkowski metric',
    'explanation': "The paper extends the Weighted K-Means method to the Minkowski metric for measuring distances.",
    'chapter_information': 'Minkowski Metric Paper'
}

minkowski_metric_paper_question_3 = {
    'question': "How are the feature weights updated in the proposed Minkowski metric Weighted K-Means?",
    'options_list': [
        'By minimizing the sum of squared distances',
        'By using a gradient descent method',
        'By applying the first order optimality condition with respect to the Minkowski metric',
        'By assigning equal weights to all features'
    ],
    'correct_answer': 'By applying the first order optimality condition with respect to the Minkowski metric',
    'explanation': "The feature weights in the Minkowski metric Weighted K-Means are updated by applying the first order optimality condition, ensuring they are non-negative and sum to unity.",
    'chapter_information': 'Minkowski Metric Paper'
}

minkowski_metric_paper_question_4 = {
    'question': "What is the effect of using a higher Minkowski exponent \( b \) on the feature weights?",
    'options_list': [
        'Increases the influence of all features equally',
        'Decreases the influence of noise features',
        'Makes all features equally important',
        'Has no effect on the clustering results'
    ],
    'correct_answer': 'Decreases the influence of noise features',
    'explanation': "A higher Minkowski exponent \( b \) decreases the influence of noise features by assigning them lower weights in the clustering process.",
    'chapter_information': 'Minkowski Metric Paper'
}

minkowski_metric_paper_question_5 = {
    'question': "What is the primary advantage of initializing K-Means with anomalous clusters?",
    'options_list': [
        'Reduces computational complexity',
        'Ensures convergence to the global minimum',
        'Provides better cluster recovery in the presence of noise',
        'Simplifies the implementation of the algorithm'
    ],
    'correct_answer': 'Provides better cluster recovery in the presence of noise',
    'explanation': "Initializing K-Means with anomalous clusters helps in better cluster recovery, especially in the presence of noise, by starting from more distinct centroids.",
    'chapter_information': 'Minkowski Metric Paper'
}

minkowski_metric_paper_question_6 = {
    'question': "Given the Minkowski metric \( p \)-norm between points \( x = [1, 2] \) and \( y = [3, 4] \) with \( p = 3 \), compute the distance.",
    'options_list': [
        '2.924',
        '3.301',
        '3.914',
        '4.641'
    ],
    'correct_answer': '3.301',
    'explanation': "The Minkowski distance with \( p = 3 \) is calculated as \( ((3-1)^3 + (4-2)^3)^{1/3} = 3.301 \).",
    'chapter_information': 'Minkowski Metric Paper'
}


KC_MPC_QUESTIONS = []
global_items = list(globals().items())
# print(global_items)

for name, value in global_items:
    if not name.startswith('_'):
        KC_MPC_QUESTIONS.append(value)

WEEK_1_MPC = KC_MPC_QUESTIONS[:-1]
